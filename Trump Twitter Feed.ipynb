{"type":"cell","id":"00e0c1","pos":28,"input":"15.Now we'll explore Trump's most frequently used words. To do this, create a loop that iterates through each tweet text and saves them all to one long string called \"all_tweets\".","cell_type":"markdown"}
{"type":"cell","id":"0217a6","pos":22,"input":"12.Next, plot this dictionary using a histogram. Hint: google \"python plot dictionary histogram\" in order to do this. \n\nPut the line \"plt.rcParams['figure.figsize'] = [10, 5]\" BEFORE you plot the histogram in order to see the dates along the x-axis clearly.","cell_type":"markdown"}
{"type":"cell","id":"031bc6","pos":34,"input":"18.Create a dictionary called counts whose key is each word and whose value is the number of times that that word occurs.","cell_type":"markdown"}
{"type":"cell","id":"102f2f","pos":3,"input":"import json\n\njs=[]\n\n#load older tweets\nwith open('old_tweets.json') as json_data1:\n    js1 = json.load(json_data1)\n\n#load newer tweets\nwith open('new_tweets.json') as json_data2:\n    js2 = json.load(json_data2)\n\n#merge both tweets\nfor j in range(len(js1)):\n    js.append(js1[j])\n\nfor j in range(len(js2)):\n    for i in range(len(js2[j])):\n        js.append(js2[j][i])\n\n#delete duplicates based on creation time\ndatelist=[]\ncount=0\ndups_removed=[]\n\nfor j in range(len(js)):\n    date=js[j]['created_at']\n    if date not in datelist: #remove duplicates\n        datelist.append(date)\n        count = count + 1\n        dups_removed.append(js[j])\n\n#update donalddata.json to include all non-duplicate tweets\noutfile = open('donalddata.json', 'w')\njson.dump(dups_removed, outfile)\noutfile.close()\n\nprint('number of unique tweets', count)","output":{"0":{"name":"stdout","output_type":"stream","text":"number of unique tweets 6167\n"}},"cell_type":"code","exec_count":2}
{"type":"cell","id":"1277e3","pos":13,"input":"#insert 7","cell_type":"code","exec_count":4,"collapsed":true}
{"type":"cell","id":"1b0344","pos":46,"input":"import re\n\nall_tweets = re.sub(r\"http\\S+\", \"\", all_tweets) #remove hyperlinks\nall_tweets = re.sub(r\"amp\\S+\", \"\", all_tweets) #remove ampersand symbol\nall_tweets = re.sub(r\"\\t\", \"\", all_tweets)  # remove tabs\nall_tweets = re.sub(r\"\\v\", \"\", all_tweets)  # remove vertical space\nall_tweets = re.sub(r\"\\r\", \"\", all_tweets)  # remove carriage return\nall_tweets = re.sub(r\"\\n\", \"\", all_tweets)  # remove new lines\nall_tweets = re.sub(r\"\\(\", \"\", all_tweets)  # remove parenthesis\nall_tweets = re.sub(r\"\\)\", \"\", all_tweets)  # remove parenthesis\nall_tweets = re.sub(r\"\\.\\.\\.\", \"\", all_tweets)  # remove ...\nall_tweets = re.sub(r\"\\. \\. \\. \", \"\", all_tweets)  # remove . . .\nall_tweets = re.sub(r\"\\\"\", \"\", all_tweets)  # remove quotations\nall_tweets = re.sub(r\"!\", \"! \", all_tweets)  # insert space after !\nall_tweets = re.sub(r\"\\.\", \". \", all_tweets)  # insert space after .\nall_tweets = re.sub(r\"\\?\", \"? \", all_tweets)  # insert space after ?","cell_type":"code","collapsed":true}
{"type":"cell","id":"1ce0ad","pos":35,"input":"#insert 18","cell_type":"code","exec_count":14,"collapsed":true}
{"type":"cell","id":"1d7349","pos":50,"input":"#insert 26","cell_type":"code","collapsed":true}
{"type":"cell","id":"222d3a","pos":39,"input":"#insert 20","cell_type":"code","exec_count":16,"collapsed":true}
{"type":"cell","id":"2a685c","pos":59,"input":"Optional - Make a chatbot of another celebrity.","cell_type":"markdown"}
{"type":"cell","id":"2fa955","pos":1,"input":"import twurl2\nimport json\nimport hidden\n\noutfile = open('new_tweets.json', 'w')\nwrap_list=[] #since I need to make a twitter API call repeatedly I will wrap the JSON info into a list\n\nTWITTER_URL = 'https://api.twitter.com/1.1/statuses/user_timeline.json'\nacct = 'realdonaldtrump'\ntwittercount=200 #pull 200 tweets at a time (the max)\nsecrets = hidden.oauth()\nfull_url=''.join([TWITTER_URL,'?','count=',str(twittercount),'&', 'screen_name=', acct])\nuser_timeline = twurl2.oauth_req( full_url, secrets['token_key'], secrets['token_secret'], \"GET\" )\njs=json.loads(user_timeline)\nwrap_list.append(js)\n\n#twitter gives an ID with each tweet...keep hitting the twitter API until you run out of new IDs\nold_max_id=0\nmax_id=js[len(js) - 1]['id']\n\nwhile old_max_id!=max_id:\n    old_max_id=max_id\n    full_url=''.join([TWITTER_URL,'?','count=',str(twittercount),'&', 'screen_name=', acct, '&', 'max_id=', str(max_id)])\n    user_timeline = twurl2.oauth_req( full_url, secrets['token_key'], secrets['token_secret'], \"GET\" )\n    js = json.loads(user_timeline)\n\n    max_id=js[len(js) - 1]['id']\n    wrap_list.append(js)\n\njson.dump(wrap_list, outfile)\noutfile.close()\n\nprint('newest_tweet', wrap_list[0][0]['text'],wrap_list[0][0]['created_at'])\nprint('')\nprint('oldest_tweet', wrap_list[-1][0]['text'],wrap_list[-1][0]['created_at'])","output":{"0":{"name":"stdout","output_type":"stream","text":"newest_tweet Today, my Administration is launching the most sweeping action in history to lower the price of prescription drugsâ€¦ https://t.co/YHscW623cr Fri May 11 19:30:16 +0000 2018\noldest_tweet Ungrateful TRAITOR Chelsea Manning, who should never have been released from prison, is now calling President Obama a weak leader. Terrible! Thu Jan 26 11:04:24 +0000 2017\n"}},"cell_type":"code","exec_count":1}
{"type":"cell","id":"30bba2","pos":25,"input":"#insert 13","cell_type":"code","exec_count":10,"collapsed":true}
{"type":"cell","id":"315cb9","pos":42,"input":"22.Now open the twitterword.html file in a web browser to view the word cloud. Take a screenshot of it and save it as twitter.jpg. Then run the code to see the screenshot below.","cell_type":"markdown"}
{"type":"cell","id":"3847d3","pos":6,"input":"4.Create three lists for the tweet texts, created_at, and number_of_retweets data. Then store them in a single pandas dataframe called df.","cell_type":"markdown"}
{"type":"cell","id":"38859f","pos":7,"input":"#insert 4","cell_type":"code","exec_count":2,"collapsed":true}
{"type":"cell","id":"3acfd8","pos":44,"input":"23.The word cloud was created using the D3 JavaScript library for visualizing data. It is super hot right now! You could pretty much get hired right now if you are good with it. Check out some other visualizations you can do with it here:\n\nhttps://github.com/d3/d3/wiki/Gallery\n","cell_type":"markdown"}
{"type":"cell","id":"3d1930","pos":60,"input":"#insert optional","cell_type":"code","collapsed":true}
{"type":"cell","id":"3d712b","pos":21,"input":"#insert 11","cell_type":"code","exec_count":8,"collapsed":true}
{"type":"cell","id":"468143","pos":49,"input":"26.Okay, now gets to the fun part where we actually get to make a chatbot. We'll do this using Markov chains. A Markov chain is a randomly determined model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. What does this mean?\n\nWe'll make a key-value dictionary where each key is a two word phrase and each value is a list containing all the possible single words that come after that phrase. Here's a concrete example. Read it carefully, paying special attention to the \"and i\" phrase.\n\n\"hi my name is Al and i live in a box that i like very much and i can live in there as long as i want\"\n\n\"hi my\" -> [\"name\"]\n\n\"my name\" -> [\"is\"]\n\n\"name is\" -> [\"Al\"]\n\n\"is Al\" -> [\"and\"]\n\n\"Al and\" -> [\"i\"]\n\n\"and i\" -> [\"live\"]\n\n........\n\n\"and i\" -> [\"live\", \"can\"]\n\n........\n\n\"i can\" -> [\"live\"]\n\n......\n\nMake a dictionary that does this type of Markov chain for all_tweets called word_dict below. Here are a few helpful hints:\n\nYou can't iterate ALL the way until the end of the list (or else you'll go out of index). You may need to stop a few words short.\n\nFor each new two word phrase, store the first word value to a LIST. Then, if that two word phrase comes around again, you can append the next possible word to that list.","cell_type":"markdown"}
{"type":"cell","id":"4aa6d2","pos":36,"input":"19.Create a sorted list of tuples called tuple_list in reverse order of his most frequently used words. Only print the words that occur at least ten times.","cell_type":"markdown"}
{"type":"cell","id":"52baf6","pos":26,"input":"14.What were the texts of those tweets on that date? Hint: you can do this in one line.","cell_type":"markdown"}
{"type":"cell","id":"607889","pos":19,"input":"#insert 10","cell_type":"code","exec_count":7,"collapsed":true}
{"type":"cell","id":"63fe9c","pos":27,"input":"#insert 14","cell_type":"code","exec_count":11,"collapsed":true}
{"type":"cell","id":"66f429","pos":38,"input":"20.One last thing...word cloud visualizations are kind of a hot thing right now. Let's make one, but get rid of the boring words like \"the\" that aren't very interesting. Recreate the count dictionary in number 18 above but add keys that are not in the boring list below:\n\nboring_words=['at', 'be','was', 'by', 'our','do','so','amp','by','it','its','at','by' 'from', 'as', 'but','am','of', 'a', 'you', 'on', 'the', 'is', 'to', 'and', 'in', 'has', 'are', 'not', 'an', 'in', 'or', 'for', 'who', 'that', 'have', 'there', 'just', 'their', 'were', 'what' , 'with', 'will', 'than', 'about', 'this','if','from','would','been','had']\n\n","cell_type":"markdown"}
{"type":"cell","id":"6786ad","pos":56,"input":"#insert 29","cell_type":"code","collapsed":true}
{"type":"cell","id":"6ac573","pos":29,"input":"#insert 15","cell_type":"code","exec_count":12,"collapsed":true}
{"type":"cell","id":"6c19b6","pos":23,"input":"#insert 12","cell_type":"code","exec_count":9,"collapsed":true}
{"type":"cell","id":"6dac03","pos":16,"input":"9.How many tweets has he sent between midnight and 4:00 am in this dataset? You can do this in one line.","cell_type":"markdown"}
{"type":"cell","id":"6f1272","pos":8,"input":"5.Which did the tweet that had the most retweets say? ","cell_type":"markdown"}
{"type":"cell","id":"7943a2","pos":45,"input":"### Chatbot\n24.Now let's make a Donald Trump chatbot that uses his previous tweets to create new tweets. We'll go back to the string all_tweets that contains all of his tweets before punctuation is removed.\n\nFirst, we'll remove certain punctuation (and hashtags and hyperlinks) and put spaces between other punctuation. We can do that most easily using regular expressions. The regular expression package is very powerful - there are loads of online tutorials for using regular expressions to manipulate strings. I highly recommend reading about them. But in the meantime, you can just read my code carefully below and run the code:","cell_type":"markdown"}
{"type":"cell","id":"7e63d2","pos":43,"input":"double click into this cell and then run it\n<img src=\"twitter.jpg\" style=\"width: 200px;\"/>","cell_type":"markdown"}
{"type":"cell","id":"81e51d","pos":5,"input":"# insert 3","cell_type":"code","exec_count":1,"collapsed":true}
{"type":"cell","id":"823830","pos":30,"input":"16.Make the entire string lower case (since we want Hillary and hillary to be equivalent) and resave it as \"cleaned_tweets\".","cell_type":"markdown"}
{"type":"cell","id":"8333d2","pos":0,"input":"In this project, you will use your knowledge of datetime and matplotlib to plot the number of Donald's tweets versus the a.) date, b.) day of the week and c.) time of the day. Also, you will analyze his most used words. \n\n1.First, to get his tweets, we'll actually need to make a loop and hit the twitter API multiple times (since he's got a lotttt of tweets and Twitter has a limit to the amount of tweets that you can request at once.) This next code will get all of these tweets and save them to a file called new_tweets.json:","cell_type":"markdown"}
{"type":"cell","id":"8b241f","pos":57,"input":"30.Run the last several lines of code several times. Copy and paste the new_tweet that sounds most realistic below.","cell_type":"markdown"}
{"type":"cell","id":"92e1a2","pos":54,"input":"#insert 28","cell_type":"code","collapsed":true}
{"type":"cell","id":"933554","pos":4,"input":"3.Load the donalddata.json data that you have just created back in in json format.","cell_type":"markdown"}
{"type":"cell","id":"99bbdb","pos":10,"input":"6.Let's convert the Twitter data (in UTC time) to Eastern Time Zone time. Here we create a new column called eastern_time_zone:","cell_type":"markdown"}
{"type":"cell","id":"9aff15","pos":52,"input":"#insert 27","cell_type":"code","collapsed":true}
{"type":"cell","id":"a5e854","pos":9,"input":"#insert 5","cell_type":"code","exec_count":3,"collapsed":true}
{"type":"cell","id":"a7fd41","pos":31,"input":"#insert 16","cell_type":"code","exec_count":1,"collapsed":true}
{"type":"cell","id":"aa4396","pos":24,"input":"13.On which date did he tweet the most? Hint: you can create a sorted list of tuples if you wish.","cell_type":"markdown"}
{"type":"cell","id":"b22387","pos":12,"input":"7.Create a new column that includes just the hour of each tweets (use pandas built in datetime capabilities to do this in one line). Then plot a histogram of the date versus the number of tweets on that date. \n\n1. Label your axes.\n\n2. Use bins = np.range(-.5,24.5,1) to center each bin at the hour and rwidth=0.9 to provide some separation.\n\n3. Google how to add x-axis tick labels at each hour mark \"0,1,2,3...23\"\n\nMake sure the bins and the labels are centered nicely.","cell_type":"markdown"}
{"type":"cell","id":"b27f93","pos":17,"input":"#insert 9","cell_type":"code","exec_count":6,"collapsed":true}
{"type":"cell","id":"bbbb9a","pos":11,"input":"import datetime\nimport pytz\nfrom dateutil.parser import parse\n\ntz = pytz.timezone('US/Eastern')\n\ntime_zone = []\nfor j in range(len(js)):\n    time_zone.append(parse(js[j]['created_at']).astimezone(tz))\n    \ndf['eastern_time_zone'] = time_zone\n\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>created_at</th>\n      <th>retweet_count</th>\n      <th>text</th>\n      <th>eastern_time_zone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Thu Mar 23 01:04:32 +0000 2017</td>\n      <td>2896</td>\n      <td>RT @mitchellvii: Trump always ends up being ri...</td>\n      <td>2017-03-22 21:04:32-04:00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Thu Mar 23 01:03:18 +0000 2017</td>\n      <td>1625</td>\n      <td>RT @mitchellvii: EXACTLY AS I SAID - House Int...</td>\n      <td>2017-03-22 21:03:18-04:00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wed Mar 22 13:09:35 +0000 2017</td>\n      <td>10233</td>\n      <td>Big day for healthcare. Working hard!</td>\n      <td>2017-03-22 09:09:35-04:00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Tue Mar 21 18:12:05 +0000 2017</td>\n      <td>13207</td>\n      <td>Today on #NationalAgDay, we honor our great Am...</td>\n      <td>2017-03-21 14:12:05-04:00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Tue Mar 21 17:33:23 +0000 2017</td>\n      <td>13448</td>\n      <td>Honored to sign S.442 today. With this legisla...</td>\n      <td>2017-03-21 13:33:23-04:00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"output_type":"execute_result","exec_count":11}},"cell_type":"code","exec_count":11}
{"type":"cell","id":"c0f171","pos":53,"input":"28.Update the starting_phrase to now be the last two words of the string, with a space in between.","cell_type":"markdown"}
{"type":"cell","id":"c3937c","pos":58,"input":"#insert 30","cell_type":"code","collapsed":true}
{"type":"cell","id":"c6c434","pos":41,"input":"# ##########################################\n#plot counts using d3, to view the visualization open the twitterword.htm file in a web browser\n# ##########################################\nx = sorted(counts, key=counts.get, reverse=True)\nhighest = None\nlowest = None\nfor k in x[:100]:\n    if highest is None or highest < counts[k] :\n        highest = counts[k]\n    if lowest is None or lowest > counts[k] :\n        lowest = counts[k]\n\n# Spread the font sizes across 20-100 based on the count\nbigsize = 80\nsmallsize = 20\n\nfhand = open('donaldwords.js','w')\nfhand.write(\"donaldwords = [\")\nfirst = True\nfor k in x[:100]:\n    if not first : fhand.write( \",\\n\")\n    first = False\n    size = counts[k]\n    size = (size - lowest) / float(highest - lowest)\n    size = int((size * bigsize) + smallsize)\n    fhand.write(\"{text: '\"+k+\"', size: \"+str(size)+\"}\")\nfhand.write( \"\\n];\\n\")\n\nprint (\"Output written to donaldwords.js\")\n","output":{"0":{"name":"stdout","output_type":"stream","text":"Output written to donaldwords.js\n"}},"cell_type":"code","exec_count":25}
{"type":"cell","id":"cbb4cc","pos":33,"input":"import string\ncleaned_tweets = cleaned_tweets.translate(str.maketrans('','',string.punctuation))\ncleaned_tweets[0:100]","cell_type":"code","exec_count":2,"collapsed":true}
{"type":"cell","id":"ce2cad","pos":15,"input":"#insert 8","cell_type":"code","exec_count":5,"collapsed":true}
{"type":"cell","id":"cf578f","pos":14,"input":"8.From the graph above, which hour does he tweet at most often?","cell_type":"markdown"}
{"type":"cell","id":"d04df6","pos":40,"input":"21.We'll save the words and their frequencies to a javascript file that we can view on a webpage. Here's the code.\n","cell_type":"markdown"}
{"type":"cell","id":"d82c14","pos":37,"input":"#insert 19","cell_type":"code","exec_count":15,"collapsed":true}
{"type":"cell","id":"da9d63","pos":47,"input":"25.Split the string all_tweets into a list of words called words. Remove words that contain just punctuation in the following list:\n\nbad_words=['â€¦', '.', '!', '?', ',']","cell_type":"markdown"}
{"type":"cell","id":"dae2a8","pos":18,"input":"10.Make a histogram of day of week vs number of tweets using pandas built in datetime capabilities. Recall that Monday corresponds to 0. \n\nChange the x-axis labels so that you see \"Mon, Tues, etc.\" instead of \"0,1,2....\" You will probably need to google this.\n\nMake sure the bins and the labels are centered nicely.","cell_type":"markdown"}
{"type":"cell","id":"deb8ae","pos":51,"input":"27.Now randomly choose a key (two word phrase) to start with and then take that key and print a random value of that key (single word that follows). To do this, go back to Unit 4 to remember how to use random.choice and random.randint.\n\nCreate a string called new_tweet that contains the random initial starting phrase (called starting_phrase) and the following word, with a space in between.\n\nCapitalize the starting word (hint: use .capitalize())","cell_type":"markdown"}
{"type":"cell","id":"e87b0b","pos":2,"input":"2.Actually, Donald has older tweets than this. The Twitter API just doesn't let us access them. Luckily, Lauren has been saving his tweets for the last several years so we can merge the newer tweets that you just scraped with the older ones that she did in order to have a more complete data set. In the following code, we'll merge your list with hers.","cell_type":"markdown"}
{"type":"cell","id":"ecd146","pos":20,"input":"11.Next, we'll want to make a bar chart for date versus number of tweets. This will take a couple of steps. First, create a dictionary called count_days such that the key is the date (just the month-day-year - not the hour or other stuff - you can do this easily) and the value is the number of tweets on that date. ","cell_type":"markdown"}
{"type":"cell","id":"f289bf","pos":32,"input":"17.Also, we'll want to strip all of the punctuation. Do do that, we can use the following code.","cell_type":"markdown"}
{"type":"cell","id":"f4aa67","pos":48,"input":"#insert 25","cell_type":"code","collapsed":true}
{"type":"cell","id":"f90f2c","pos":55,"input":"29.While the new tweet is less than 140 characters, create a loop that continues to add new words to the new_tweet string by generating a new random number and a new word that follows the last starting_phrase. Each time through the loop, update the starting phrase.\n\nNote: You will need to use a try/except because not all pairs of words that you put together are in the word_dict. If you get to a pair that isn't in the word dict, proceed as follows:\n\n\na.If the pair ends in a period, simply end the sentence.\n\nb. If the pair does not end in a period, generate a new random starting phrase and continue creating a new sentence.","cell_type":"markdown"}
{"type":"file","last_load":1526445392469}
{"type":"settings","kernel":"python3","backend_state":"running","trust":false,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"kernel_usage":{"cpu":0,"memory":76992512},"kernel_state":"idle"}